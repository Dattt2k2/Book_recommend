{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.0\n",
      "Số lượng bản ghi đánh giá ban đầu: 3000000\n",
      "Số lượng bản ghi sách ban đầu: 212404\n",
      "\n",
      "Kiểm tra giá trị null/rỗng trong dữ liệu đánh giá:\n",
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+\n",
      "| Id|Title|  Price|User_id|profileName|review/helpfulness|review/score|review/time|review/summary|review/text|\n",
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+\n",
      "|  0|  208|2517579| 562250|     562250|               367|         130|         27|            65|         43|\n",
      "+---+-----+-------+-------+-----------+------------------+------------+-----------+--------------+-----------+\n",
      "\n",
      "\n",
      "Kiểm tra giá trị null/rỗng trong dữ liệu sách:\n",
      "+-----+-----------+-------+-----+-----------+---------+-------------+--------+----------+------------+\n",
      "|Title|description|authors|image|previewLink|publisher|publishedDate|infoLink|categories|ratingsCount|\n",
      "+-----+-----------+-------+-----+-----------+---------+-------------+--------+----------+------------+\n",
      "|    1|      68357|  31251|51191|      24055|    73130|        25844|   24301|     40524|      148552|\n",
      "+-----+-----------+-------+-----+-----------+---------+-------------+--------+----------+------------+\n",
      "\n",
      "\n",
      "Thống kê về Rating:\n",
      "+-------+------------------+\n",
      "|summary|            Rating|\n",
      "+-------+------------------+\n",
      "|  count|           2981936|\n",
      "|   mean|1656.8604219708309|\n",
      "| stddev|1427549.9863179324|\n",
      "|    min|               1.0|\n",
      "|    25%|               4.0|\n",
      "|    50%|               5.0|\n",
      "|    75%|               5.0|\n",
      "|    max|        1.295568E9|\n",
      "+-------+------------------+\n",
      "\n",
      "Số lượng bản ghi đánh giá sau khi lọc dữ liệu không hợp lệ: 2420420\n",
      "Số lượng bản ghi sách sau khi lọc: 212403\n",
      "Số lượng bản ghi đánh giá sau khi lấy mẫu: 484830\n",
      "Số lượng người dùng độc nhất: 304070\n",
      "Số lượng sách độc nhất: 108195\n",
      "Số lượng bản ghi đánh giá cuối cùng: 484793\n",
      "\n",
      "Dữ liệu đánh giá sau khi xử lý:\n",
      "+--------------+---------+----------+---------+------+\n",
      "|        UserID|userIndex|    BookID|bookIndex|Rating|\n",
      "+--------------+---------+----------+---------+------+\n",
      "|A2RSSXTDZDUSH4| 175228.0|0826414346|  71632.0|   5.0|\n",
      "| AUR0VA5H0C66C| 294722.0|0595344550|  15324.0|   1.0|\n",
      "| ACO23CG8K8T77| 262389.0|0595344550|  15324.0|   5.0|\n",
      "| AJV5HX8BBZKEP| 275498.0|0595344550|  15324.0|   4.0|\n",
      "|A2XXVRH6VJ8S7Q| 186253.0|0595344550|  15324.0|   5.0|\n",
      "+--------------+---------+----------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Số lượng mẫu huấn luyện: 387736\n",
      "Số lượng mẫu kiểm thử: 97057\n"
     ]
    }
   ],
   "source": [
    "# # Khởi tạo Spark Session\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"BookRecommendationSystem\") \\\n",
    "#     .config(\"spark.driver.memory\", \"4g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"4g\") \\\n",
    "#     .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "#     .config(\"spark.default.parallelism\", \"10\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# # Hiển thị thông tin phiên bản Spark\n",
    "# print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "# # Tải dữ liệu từ HDFS\n",
    "\n",
    "# # Đường dẫn đến dữ liệu trên HDFS\n",
    "# books_file = \"hdfs://namenode:9000/user/hadoop/book_recommendation/books_data.csv\"\n",
    "# ratings_file = \"hdfs://namenode:9000/user/hadoop/book_recommendation/Books_rating.csv\"\n",
    "\n",
    "# # Đọc dữ liệu\n",
    "# try:\n",
    "#     books_df = spark.read.csv(books_file, header=True, inferSchema=True)\n",
    "#     ratings_df = spark.read.csv(ratings_file, header=True, inferSchema=True)\n",
    "#     print(\"Đã tải dữ liệu từ HDFS thành công!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi tải dữ liệu từ HDFS: {str(e)}\")\n",
    "#     # Dự phòng: Tải từ local nếu HDFS không hoạt động\n",
    "#     books_df = spark.read.csv(\"/path/to/local/books_data.csv\", header=True, inferSchema=True)\n",
    "#     ratings_df = spark.read.csv(\"/path/to/local/Books_rating.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Khởi tạo Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, isnan, count, isnull, lit\n",
    "from pyspark.sql.types import FloatType, StringType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookRecommendationSystem\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "    .config(\"spark.default.parallelism\", \"10\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "# Đường dẫn đến dữ liệu trên HDFS\n",
    "books_file = \"hdfs://namenode:9000/user/hadoop/book_recommendation/books_data.csv\"\n",
    "ratings_file = \"hdfs://namenode:9000/user/hadoop/book_recommendation/Books_rating.csv\"\n",
    "\n",
    "# Tải dữ liệu\n",
    "book_rating = spark.read.csv(\n",
    "    ratings_file,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "book_data = spark.read.csv(\n",
    "    books_file,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Kiểm tra số lượng bản ghi ban đầu\n",
    "print(f\"Số lượng bản ghi đánh giá ban đầu: {book_rating.count()}\")\n",
    "print(f\"Số lượng bản ghi sách ban đầu: {book_data.count()}\")\n",
    "\n",
    "# Kiểm tra giá trị null/rỗng\n",
    "print(\"\\nKiểm tra giá trị null/rỗng trong dữ liệu đánh giá:\")\n",
    "book_rating.select([count(when(isnull(c) | isnan(c) | (col(c) == \"\"), c)).alias(c) for c in book_rating.columns]).show()\n",
    "\n",
    "print(\"\\nKiểm tra giá trị null/rỗng trong dữ liệu sách:\")\n",
    "book_data.select([count(when(isnull(c) | isnan(c) | (col(c) == \"\"), c)).alias(c) for c in book_data.columns]).show()\n",
    "\n",
    "# Đổi tên cột và ép kiểu dữ liệu\n",
    "ratings_raw = book_rating.select(\n",
    "    col(\"User_id\").alias(\"UserID\"),\n",
    "    col(\"Id\").alias(\"BookID\"),\n",
    "    col(\"title\"),\n",
    "    col(\"review/score\").cast(FloatType()).alias(\"Rating\")\n",
    ")\n",
    "\n",
    "books_raw = book_data.select(\"title\", \"categories\")\n",
    "\n",
    "# Kiểm tra phạm vi của Rating\n",
    "print(\"\\nThống kê về Rating:\")\n",
    "ratings_raw.select(\"Rating\").summary().show()\n",
    "\n",
    "# Loại bỏ các giá trị không hợp lệ\n",
    "ratings_clean = ratings_raw.filter(\n",
    "    # Loại bỏ null\n",
    "    col(\"UserID\").isNotNull() & \n",
    "    col(\"BookID\").isNotNull() & \n",
    "    col(\"Rating\").isNotNull() &\n",
    "    # Loại bỏ chuỗi rỗng\n",
    "    (col(\"UserID\") != \"\") &\n",
    "    (col(\"BookID\") != \"\") &\n",
    "    # Đảm bảo rating trong phạm vi hợp lệ (1-5)\n",
    "    (col(\"Rating\") >= 1) & \n",
    "    (col(\"Rating\") <= 5)\n",
    ")\n",
    "\n",
    "books_clean = books_raw.filter(\n",
    "    col(\"title\").isNotNull() &\n",
    "    (col(\"title\") != \"\")\n",
    ")\n",
    "\n",
    "# Kiểm tra số lượng bản ghi sau khi lọc\n",
    "print(f\"Số lượng bản ghi đánh giá sau khi lọc dữ liệu không hợp lệ: {ratings_clean.count()}\")\n",
    "print(f\"Số lượng bản ghi sách sau khi lọc: {books_clean.count()}\")\n",
    "\n",
    "# Lấy mẫu nếu dữ liệu quá lớn (tránh lỗi bộ nhớ)\n",
    "sample_ratio = 0.2  # Có thể điều chỉnh\n",
    "ratings_sampled = ratings_clean.sample(fraction=sample_ratio, seed=42)\n",
    "print(f\"Số lượng bản ghi đánh giá sau khi lấy mẫu: {ratings_sampled.count()}\")\n",
    "\n",
    "# Kiểm tra số lượng người dùng và sách độc nhất\n",
    "distinct_users = ratings_sampled.select(\"UserID\").distinct().count()\n",
    "distinct_books = ratings_sampled.select(\"BookID\").distinct().count()\n",
    "print(f\"Số lượng người dùng độc nhất: {distinct_users}\")\n",
    "print(f\"Số lượng sách độc nhất: {distinct_books}\")\n",
    "\n",
    "# Chuyển đổi ID thành chỉ số sử dụng StringIndexer\n",
    "userIndexer = StringIndexer(\n",
    "    inputCol=\"UserID\", \n",
    "    outputCol=\"userIndex\", \n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "bookIndexer = StringIndexer(\n",
    "    inputCol=\"BookID\", \n",
    "    outputCol=\"bookIndex\", \n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Áp dụng StringIndexer\n",
    "user_indexer_model = userIndexer.fit(ratings_sampled)\n",
    "ratings_indexed = user_indexer_model.transform(ratings_sampled)\n",
    "\n",
    "book_indexer_model = bookIndexer.fit(ratings_indexed)\n",
    "ratings_indexed = book_indexer_model.transform(ratings_indexed)\n",
    "\n",
    "# Loại bỏ các giá trị null sau khi indexing (đề phòng)\n",
    "ratings_final = ratings_indexed.na.drop()\n",
    "\n",
    "print(f\"Số lượng bản ghi đánh giá cuối cùng: {ratings_final.count()}\")\n",
    "\n",
    "# Lưu labels để dùng sau\n",
    "user_labels = user_indexer_model.labels\n",
    "book_labels = book_indexer_model.labels\n",
    "\n",
    "# Tạo ánh xạ từ index sang ID gốc (để sử dụng sau này)\n",
    "user_index_to_id = {i: label for i, label in enumerate(user_labels)}\n",
    "book_index_to_id = {i: label for i, label in enumerate(book_labels)}\n",
    "\n",
    "# Hiển thị dữ liệu đã xử lý\n",
    "print(\"\\nDữ liệu đánh giá sau khi xử lý:\")\n",
    "ratings_final.select(\"UserID\", \"userIndex\", \"BookID\", \"bookIndex\", \"Rating\").show(5)\n",
    "\n",
    "# Phân chia dữ liệu thành tập huấn luyện và tập kiểm thử\n",
    "train, test = ratings_final.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Số lượng mẫu huấn luyện: {train.count()}\")\n",
    "print(f\"Số lượng mẫu kiểm thử: {test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được lưu thành công tại: hdfs://namenode:9000/user/hadoop/book_recommendation/models/als_model\n",
      "Root Mean Square Error (RMSE) = 1.4173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    userCol=\"userIndex\",\n",
    "    itemCol=\"bookIndex\",\n",
    "    ratingCol=\"Rating\",\n",
    "    coldStartStrategy=\"drop\",  # Quan trọng để xử lý các giá trị NaN\n",
    "    nonnegative=True\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model = als.fit(train)\n",
    "\n",
    "hdfs_model_path = \"hdfs://namenode:9000/user/hadoop/book_recommendation/models/als_model\"\n",
    "\n",
    "try:\n",
    "    # Lưu mô hình\n",
    "    model.write().overwrite().save(hdfs_model_path)\n",
    "    print(f\"Mô hình đã được lưu thành công tại: {hdfs_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi lưu mô hình: {str(e)}\")\n",
    "    \n",
    "    # Nếu không thể lưu vào HDFS, thử lưu vào thư mục local\n",
    "    try:\n",
    "        local_model_path = \"/home/jovyan/work/notebooks/als_model\"\n",
    "        model.write().overwrite().save(local_model_path)\n",
    "        print(f\"Mô hình đã được lưu thành công vào thư mục local: {local_model_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Lỗi khi lưu mô hình vào thư mục local: {str(e2)}\")\n",
    "\n",
    "# Dự đoán\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"Rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Square Error (RMSE) = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+------+---------+---------+----------+\n",
      "|        UserID|    BookID|               title|Rating|userIndex|bookIndex|prediction|\n",
      "+--------------+----------+--------------------+------+---------+---------+----------+\n",
      "|A2F6N60Z96CAJI|B0007PC4W0|I'll Be Watching You|   4.0|     22.0|  13934.0| 2.9670706|\n",
      "|A2F6N60Z96CAJI|B000N761GW|       Halfway House|   5.0|     22.0|  11989.0|  3.805781|\n",
      "|A2F6N60Z96CAJI|1423319621|The Saboteurs (Me...|   5.0|     22.0|   4150.0| 1.8978461|\n",
      "|A2F6N60Z96CAJI|0670030554|Ready to Roll: A ...|   5.0|     22.0|  19282.0| 4.1872807|\n",
      "|A2F6N60Z96CAJI|B000QBF896|           Samaritan|   5.0|     22.0|   7112.0|  3.782685|\n",
      "+--------------+----------+--------------------+------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Square Error (RMSE) trên tập kiểm thử = 1.4173\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình\n",
    "# Dự đoán đánh giá trên tập kiểm thử\n",
    "predictions = model.transform(test)\n",
    "predictions.show(5)\n",
    "\n",
    "# Tính toán RMSE (Root Mean Square Error)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"Rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Square Error (RMSE) trên tập kiểm thử = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import explode, split, col, count, desc, avg, array, lit, udf, row_number\n",
    "# from pyspark.sql.types import ArrayType, StringType, FloatType, StructType, StructField\n",
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# # Kiểm tra dữ liệu books trước khi xử lý\n",
    "# print(\"Số lượng bản ghi sách:\", books.count())\n",
    "# print(\"Số lượng bản ghi đánh giá:\", ratings.count())\n",
    "\n",
    "# # Kiểm tra cấu trúc dữ liệu sách\n",
    "# print(\"Kiểm tra cấu trúc dữ liệu sách:\")\n",
    "# books.printSchema()\n",
    "\n",
    "# # Kiểm tra dữ liệu mẫu\n",
    "# print(\"Mẫu dữ liệu sách:\")\n",
    "# books.show(5, truncate=False)\n",
    "\n",
    "# # Tạo một hàm để trích xuất danh sách thể loại từ cột categories\n",
    "# @udf(returnType=ArrayType(StringType()))\n",
    "# def extract_categories(categories_str):\n",
    "#     if categories_str is None or categories_str == \"\":\n",
    "#         return []\n",
    "#     # Xử lý nhiều trường hợp phân cách\n",
    "#     separators = [',', '|', ';']\n",
    "#     for sep in separators:\n",
    "#         if sep in categories_str:\n",
    "#             return [cat.strip() for cat in categories_str.split(sep) if cat.strip()]\n",
    "#     # Nếu không có dấu phân cách, coi như một thể loại duy nhất\n",
    "#     return [categories_str.strip()] if categories_str.strip() else []\n",
    "\n",
    "# # Áp dụng UDF để trích xuất danh sách thể loại\n",
    "# try:\n",
    "#     books_with_categories = books.withColumn(\n",
    "#         \"category_list\", \n",
    "#         extract_categories(col(\"categories\"))\n",
    "#     )\n",
    "    \n",
    "#     # Kiểm tra kết quả\n",
    "#     print(\"Mẫu sách với danh sách thể loại:\")\n",
    "#     books_with_categories.select(\"title\", \"categories\", \"category_list\").show(5, truncate=False)\n",
    "    \n",
    "#     # Kiểm tra số lượng bản ghi có danh sách thể loại rỗng\n",
    "#     empty_categories = books_with_categories.filter(size(col(\"category_list\")) == 0).count()\n",
    "#     print(f\"Số lượng sách có danh sách thể loại rỗng: {empty_categories}\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi trích xuất thể loại: {str(e)}\")\n",
    "    \n",
    "#     # Nếu có lỗi, thử phương pháp đơn giản hơn\n",
    "#     print(\"Thử phương pháp thay thế...\")\n",
    "#     books_with_categories = books.withColumn(\n",
    "#         \"category_list\", \n",
    "#         array(col(\"categories\"))  # Tạo mảng từ một phần tử duy nhất\n",
    "#     ).filter(col(\"categories\").isNotNull() & (col(\"categories\") != \"\"))\n",
    "    \n",
    "#     print(\"Mẫu sách với danh sách thể loại (phương pháp thay thế):\")\n",
    "#     books_with_categories.select(\"title\", \"categories\", \"category_list\").show(5, truncate=False)\n",
    "\n",
    "# # Kết hợp thông tin đánh giá với thể loại sách\n",
    "# try:\n",
    "#     # Kiểm tra các cột join\n",
    "#     print(\"Kiểm tra các cột join:\")\n",
    "#     print(\"Cột 'title' trong ratings:\", \"title\" in ratings.columns)\n",
    "#     print(\"Cột 'title' trong books_with_categories:\", \"title\" in books_with_categories.columns)\n",
    "    \n",
    "#     ratings_with_info = ratings.join(\n",
    "#         books_with_categories,\n",
    "#         ratings.title == books_with_categories.title,\n",
    "#         \"left\"\n",
    "#     )\n",
    "    \n",
    "#     # Kiểm tra kết quả join\n",
    "#     matched_count = ratings_with_info.filter(col(\"category_list\").isNotNull()).count()\n",
    "#     total_count = ratings_with_info.count()\n",
    "#     print(f\"Tỷ lệ đánh giá có thông tin thể loại: {matched_count}/{total_count} ({matched_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi join dữ liệu: {str(e)}\")\n",
    "#     # Kiểm tra các giá trị trùng lặp có thể gây lỗi khi join\n",
    "#     print(\"Kiểm tra giá trị trùng lặp trong cột title của books:\")\n",
    "#     books_title_counts = books.groupBy(\"title\").count().filter(col(\"count\") > 1)\n",
    "#     print(\"Số lượng tiêu đề sách trùng lặp:\", books_title_counts.count())\n",
    "#     if books_title_counts.count() > 0:\n",
    "#         print(\"Các tiêu đề trùng lặp (top 5):\")\n",
    "#         books_title_counts.orderBy(desc(\"count\")).show(5, truncate=False)\n",
    "    \n",
    "#     # Thử join với distinct titles\n",
    "#     books_distinct = books_with_categories.dropDuplicates([\"title\"])\n",
    "#     ratings_with_info = ratings.join(\n",
    "#         books_distinct,\n",
    "#         ratings.title == books_distinct.title,\n",
    "#         \"left\"\n",
    "#     )\n",
    "\n",
    "# # Phân rã danh sách thể loại thành các hàng riêng biệt\n",
    "# try:\n",
    "#     from pyspark.sql.functions import size\n",
    "    \n",
    "#     # Lọc bỏ các đánh giá không có thông tin thể loại\n",
    "#     ratings_with_categories = ratings_with_info.filter(\n",
    "#         col(\"category_list\").isNotNull() & \n",
    "#         (size(col(\"category_list\")) > 0)\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Số lượng đánh giá có thông tin thể loại: {ratings_with_categories.count()}\")\n",
    "    \n",
    "#     # Phân rã danh sách\n",
    "#     ratings_exploded = ratings_with_categories.withColumn(\n",
    "#         \"category\", \n",
    "#         explode(col(\"category_list\"))\n",
    "#     ).filter(col(\"category\").isNotNull() & (col(\"category\") != \"\"))\n",
    "    \n",
    "#     # Kiểm tra kết quả\n",
    "#     print(\"Số lượng hàng sau khi explode:\", ratings_exploded.count())\n",
    "#     print(\"Mẫu dữ liệu sau khi explode:\")\n",
    "#     ratings_exploded.select(\"UserID\", \"BookID\", \"title\", \"Rating\", \"category\").show(5, truncate=False)\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi explode thể loại: {str(e)}\")\n",
    "#     # Kiểm tra cấu trúc của category_list\n",
    "#     print(\"Kiểm tra cấu trúc category_list:\")\n",
    "#     ratings_with_info.select(\"category_list\").distinct().limit(5).show(truncate=False)\n",
    "\n",
    "# # Tính điểm trung bình và số lượng đánh giá theo người dùng và thể loại\n",
    "# try:\n",
    "#     user_category_stats = ratings_exploded.groupBy(\"UserID\", \"category\").agg(\n",
    "#         avg(\"Rating\").alias(\"avg_rating\"),\n",
    "#         count(\"Rating\").alias(\"rating_count\")\n",
    "#     )\n",
    "    \n",
    "#     # Kiểm tra kết quả\n",
    "#     print(\"Thống kê người dùng và thể loại:\")\n",
    "#     user_category_stats.orderBy(desc(\"rating_count\")).show(5)\n",
    "    \n",
    "#     # Tạo điểm kết hợp\n",
    "#     user_favorite_categories = user_category_stats.withColumn(\n",
    "#         \"score\", \n",
    "#         col(\"avg_rating\") * col(\"rating_count\")\n",
    "#     )\n",
    "    \n",
    "#     # Xếp hạng thể loại cho mỗi người dùng\n",
    "#     window_spec = Window.partitionBy(\"UserID\").orderBy(desc(\"score\"))\n",
    "    \n",
    "#     # Sử dụng try-except để phát hiện lỗi từ row_number\n",
    "#     try:\n",
    "#         user_top_categories = user_favorite_categories.withColumn(\n",
    "#             \"rank\", \n",
    "#             row_number().over(window_spec)\n",
    "#         ).filter(col(\"rank\") <= 3)\n",
    "        \n",
    "#         # Kiểm tra kết quả\n",
    "#         print(\"Thể loại yêu thích của người dùng:\")\n",
    "#         user_top_categories.orderBy(\"UserID\", \"rank\").show(15, truncate=False)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Lỗi khi sử dụng row_number: {str(e)}\")\n",
    "        \n",
    "#         # Phương pháp thay thế: sắp xếp thủ công\n",
    "#         from pyspark.sql.functions import rank\n",
    "#         user_top_categories = user_favorite_categories.withColumn(\n",
    "#             \"rank\", \n",
    "#             rank().over(window_spec)\n",
    "#         ).filter(col(\"rank\") <= 3)\n",
    "        \n",
    "#         print(\"Thể loại yêu thích (phương pháp thay thế):\")\n",
    "#         user_top_categories.orderBy(\"UserID\", \"rank\").show(15, truncate=False)\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi tính thống kê: {str(e)}\")\n",
    "\n",
    "# # Lấy danh sách người dùng mẫu để đề xuất\n",
    "# try:\n",
    "#     sample_users = ratings.select(\"UserID\").distinct().limit(5)\n",
    "#     sample_users_list = [row.UserID for row in sample_users.collect()]\n",
    "    \n",
    "#     print(f\"Danh sách người dùng mẫu: {sample_users_list}\")\n",
    "    \n",
    "#     # Đề xuất sách cho người dùng dựa trên thể loại yêu thích\n",
    "#     recommendations = []\n",
    "    \n",
    "#     for user_id in sample_users_list:\n",
    "#         print(f\"\\nĐề xuất sách cho người dùng {user_id}:\")\n",
    "        \n",
    "#         # Lấy top thể loại yêu thích của người dùng\n",
    "#         favorite_categories = user_top_categories.filter(\n",
    "#             col(\"UserID\") == user_id\n",
    "#         ).orderBy(\"rank\").select(\"category\").collect()\n",
    "        \n",
    "#         if favorite_categories:\n",
    "#             favorite_categories_list = [row.category for row in favorite_categories]\n",
    "#             print(f\"Thể loại yêu thích: {', '.join(favorite_categories_list)}\")\n",
    "            \n",
    "#             # Lấy sách đã được đánh giá bởi người dùng\n",
    "#             rated_books = ratings.filter(col(\"UserID\") == user_id).select(\"BookID\").rdd.flatMap(lambda x: [x.BookID]).collect()\n",
    "            \n",
    "#             # Tìm sách theo từng thể loại\n",
    "#             for category in favorite_categories_list:\n",
    "#                 # Tìm sách thuộc thể loại này với rating cao mà người dùng chưa đánh giá\n",
    "#                 category_books = ratings_exploded.filter(\n",
    "#                     (col(\"category\") == category) & \n",
    "#                     (~col(\"BookID\").isin(rated_books))\n",
    "#                 ).groupBy(\"title\", \"BookID\").agg(\n",
    "#                     avg(\"Rating\").alias(\"avg_rating\"),\n",
    "#                     count(\"Rating\").alias(\"rating_count\")\n",
    "#                 ).filter(col(\"rating_count\") >= 3)  # Giảm yêu cầu về số lượng đánh giá\n",
    "                \n",
    "#                 # Sắp xếp và lấy top 3\n",
    "#                 category_recs = category_books.orderBy(desc(\"avg_rating\"), desc(\"rating_count\")).limit(3)\n",
    "                \n",
    "#                 # Thu thập kết quả\n",
    "#                 category_books_list = category_recs.collect()\n",
    "                \n",
    "#                 if category_books_list:\n",
    "#                     print(f\"\\nSách thuộc thể loại '{category}':\")\n",
    "#                     for i, book in enumerate(category_books_list, 1):\n",
    "#                         print(f\"{i}. '{book.title}' - Đánh giá trung bình: {book.avg_rating:.2f} ({book.rating_count} lượt)\")\n",
    "#                         recommendations.append((\n",
    "#                             user_id, \n",
    "#                             book.BookID, \n",
    "#                             book.title, \n",
    "#                             category, \n",
    "#                             float(book.avg_rating)\n",
    "#                         ))\n",
    "#                 else:\n",
    "#                     print(f\"Không tìm thấy sách phù hợp thuộc thể loại '{category}'\")\n",
    "#         else:\n",
    "#             print(\"Không thể xác định thể loại yêu thích.\")\n",
    "    \n",
    "#     # Tạo DataFrame từ danh sách đề xuất\n",
    "#     if recommendations:\n",
    "#         schema = StructType([\n",
    "#             StructField(\"UserID\", StringType(), False),\n",
    "#             StructField(\"BookID\", StringType(), False),\n",
    "#             StructField(\"Title\", StringType(), False),\n",
    "#             StructField(\"Category\", StringType(), False),\n",
    "#             StructField(\"AverageRating\", FloatType(), False)\n",
    "#         ])\n",
    "        \n",
    "#         recommendations_df = spark.createDataFrame(recommendations, schema)\n",
    "        \n",
    "#         print(\"\\nBảng đề xuất sách theo thể loại:\")\n",
    "#         recommendations_df.show(truncate=False)\n",
    "        \n",
    "#         # Lưu kết quả đề xuất\n",
    "#         try:\n",
    "#             recommendations_df.write.csv(\n",
    "#                 \"hdfs://namenode:9000/user/hadoop/book_recommendation/category_recommendations\", \n",
    "#                 header=True, \n",
    "#                 mode=\"overwrite\"\n",
    "#             )\n",
    "#             print(\"Đã lưu kết quả đề xuất thành công!\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Lỗi khi lưu kết quả: {str(e)}\")\n",
    "#     else:\n",
    "#         print(\"Không có đề xuất nào được tạo ra.\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi trong quá trình tạo đề xuất: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hiển thị thông tin chi tiết về các sách được gợi ý\n",
    "# # Join với dataframe sách để lấy thông tin chi tiết\n",
    "# def get_book_info(book_id):\n",
    "#     return books_df.filter(col(\"book_id\") == book_id).first()\n",
    "\n",
    "# # Hiển thị các gợi ý cùng với thông tin sách\n",
    "# for user_rec in user_recs.collect():\n",
    "#     user_id = user_rec.user_id\n",
    "#     print(f\"\\nGợi ý cho người dùng ID {user_id}:\")\n",
    "    \n",
    "#     # Lấy danh sách các sách đã được gợi ý\n",
    "#     recommendations = user_rec.recommendations\n",
    "    \n",
    "#     for i, rec in enumerate(recommendations, 1):\n",
    "#         book_id = rec.book_id\n",
    "#         predicted_rating = rec.rating\n",
    "        \n",
    "#         # Tìm thông tin sách\n",
    "#         book_info = get_book_info(book_id)\n",
    "#         if book_info:\n",
    "#             title = book_info[\"title\"] if \"title\" in book_info else \"Unknown\"\n",
    "#             author = book_info[\"author\"] if \"author\" in book_info else \"Unknown\"\n",
    "#             print(f\"{i}. '{title}' by {author} (ID: {book_id}, Predicted Rating: {predicted_rating:.2f})\")\n",
    "#         else:\n",
    "#             print(f\"{i}. Book ID: {book_id}, Predicted Rating: {predicted_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Đánh giá hiệu suất dựa trên Mean Average Precision (MAP)\n",
    "# from pyspark.ml.evaluation import RankingEvaluator\n",
    "\n",
    "# # Chuẩn bị dữ liệu cho đánh giá ranking\n",
    "# # Tạo ground truth - các sách mà người dùng đã đánh giá cao (rating >= 4)\n",
    "# ground_truth = ratings_clean_df.filter(col(\"rating\") >= 4.0) \\\n",
    "#                             .groupBy(\"user_id\") \\\n",
    "#                             .agg(expr(\"collect_list(book_id) as actual_items\"))\n",
    "\n",
    "# # Tạo danh sách các sách được gợi ý\n",
    "# users = ratings_clean_df.select(\"user_id\").distinct()\n",
    "# recommendations = model.recommendForAllUsers(20)  # 20 gợi ý cho mỗi người dùng\n",
    "# predictions_for_eval = recommendations.withColumn(\n",
    "#     \"recommended_items\", \n",
    "#     expr(\"TRANSFORM(recommendations, x -> x.book_id)\")\n",
    "# )\n",
    "\n",
    "# # Join dữ liệu ground truth và predictions\n",
    "# pred_vs_actual = predictions_for_eval.join(\n",
    "#     ground_truth, \n",
    "#     \"user_id\", \n",
    "#     \"inner\"\n",
    "# ).select(\"user_id\", \"recommended_items\", \"actual_items\")\n",
    "\n",
    "# # Tính MAP\n",
    "# rank_evaluator = RankingEvaluator(\n",
    "#     predictionCol=\"recommended_items\", \n",
    "#     labelCol=\"actual_items\", \n",
    "#     metricName=\"meanAveragePrecision\"\n",
    "# )\n",
    "\n",
    "# map_score = rank_evaluator.evaluate(pred_vs_actual)\n",
    "# print(f\"Mean Average Precision (MAP) = {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lưu mô hình để sử dụng sau này\n",
    "# hdfs_model_path = \"hdfs://namenode:9000/user/hadoop/book_recommendation/models/book_recommender_als\"\n",
    "\n",
    "\n",
    "# try:\n",
    "#     model.save(model_path)\n",
    "#     print(f\"Đã lưu mô hình tại: {model_path}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi lưu mô hình: {str(e)}\")\n",
    "#     # Lưu trên HDFS\n",
    "#     hdfs_model_path = \"hdfs://localhost:9000/user/hadoop/book_recommendation/models/book_recommender_als\"\n",
    "#     model.save(hdfs_model_path)\n",
    "#     print(f\"Đã lưu mô hình trên HDFS tại: {hdfs_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'setCallSite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Lấy danh sách mẫu người dùng để thử nghiệm\u001b[39;00m\n\u001b[1;32m     87\u001b[0m sample_users \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m User_ids \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39mUserID \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43msample_users\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Thử nghiệm hàm gợi ý\u001b[39;00m\n\u001b[1;32m     91\u001b[0m test_user_id \u001b[38;5;241m=\u001b[39m User_ids[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Lấy một người dùng từ mẫu\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1256\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Row]:\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m    [Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSCCallSiteSync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/traceback_utils.py:75\u001b[0m, in \u001b[0;36mSCCallSiteSync.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SCCallSiteSync\u001b[38;5;241m.\u001b[39m_spark_stack_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetCallSite\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_site)\n\u001b[1;32m     76\u001b[0m     SCCallSiteSync\u001b[38;5;241m.\u001b[39m_spark_stack_depth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'setCallSite'"
     ]
    }
   ],
   "source": [
    "# Tạo chức năng gợi ý sách cho người dùng cụ thể\n",
    "from pyspark.sql.functions import col, desc, expr\n",
    "\n",
    "def recommend_books_for_user(user_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Tạo gợi ý sách cho một người dùng cụ thể\n",
    "    \n",
    "    Parameters:\n",
    "    user_id: ID người dùng cần gợi ý\n",
    "    top_n: Số lượng sách gợi ý tối đa\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame chứa sách được gợi ý\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Kiểm tra xem người dùng có tồn tại trong dữ liệu không\n",
    "        if ratings.filter(col(\"UserID\") == user_id).count() == 0:\n",
    "            print(f\"Không tìm thấy dữ liệu đánh giá cho người dùng {user_id}\")\n",
    "            return spark.createDataFrame([], \"BookID STRING, predicted_rating FLOAT\")\n",
    "            \n",
    "        # Lấy sách đã được đánh giá bởi người dùng\n",
    "        rated_books = ratings.filter(col(\"UserID\") == user_id) \\\n",
    "                         .select(\"BookID\").rdd.flatMap(lambda x: [x.BookID]).collect()\n",
    "        \n",
    "        print(f\"Người dùng {user_id} đã đánh giá {len(rated_books)} sách\")\n",
    "        \n",
    "        # Tìm thể loại yêu thích của người dùng\n",
    "        if 'user_top_categories' in globals():\n",
    "            favorite_categories = user_top_categories.filter(col(\"UserID\") == user_id) \\\n",
    "                                   .orderBy(\"rank\").select(\"category\").collect()\n",
    "            \n",
    "            if favorite_categories:\n",
    "                favorite_category_list = [row.category for row in favorite_categories]\n",
    "                print(f\"Thể loại yêu thích: {', '.join(favorite_category_list)}\")\n",
    "                \n",
    "                # Tạo gợi ý dựa trên thể loại yêu thích\n",
    "                recommendations = []\n",
    "                \n",
    "                for category in favorite_category_list:\n",
    "                    # Tìm sách thuộc thể loại này với rating cao mà người dùng chưa đánh giá\n",
    "                    category_books = ratings_exploded.filter(\n",
    "                        (col(\"category\") == category) & \n",
    "                        (~col(\"BookID\").isin(rated_books))\n",
    "                    ).groupBy(\"BookID\", \"title\").agg(\n",
    "                        avg(\"Rating\").alias(\"avg_rating\"),\n",
    "                        count(\"Rating\").alias(\"rating_count\")\n",
    "                    ).filter(col(\"rating_count\") >= 2)  # Sách có ít nhất 2 đánh giá\n",
    "                    \n",
    "                    # Sắp xếp và lấy top 3 sách cho mỗi thể loại\n",
    "                    category_recs = category_books.orderBy(desc(\"avg_rating\"), desc(\"rating_count\")).limit(3)\n",
    "                    recommendations.append(category_recs)\n",
    "                \n",
    "                if recommendations:\n",
    "                    # Ghép các gợi ý từ các thể loại khác nhau\n",
    "                    combined_recs = recommendations[0]\n",
    "                    for i in range(1, len(recommendations)):\n",
    "                        combined_recs = combined_recs.union(recommendations[i])\n",
    "                    \n",
    "                    # Sắp xếp lại và lấy top_n\n",
    "                    final_recs = combined_recs.orderBy(desc(\"avg_rating\"), desc(\"rating_count\")).limit(top_n)\n",
    "                    return final_recs\n",
    "                else:\n",
    "                    print(\"Không tìm thấy gợi ý phù hợp dựa trên thể loại\")\n",
    "            else:\n",
    "                print(f\"Không tìm thấy thể loại yêu thích cho người dùng {user_id}\")\n",
    "        else:\n",
    "            print(\"Chưa phân tích thể loại yêu thích của người dùng\")\n",
    "            \n",
    "        # Fallback: Tìm sách phổ biến mà người dùng chưa đánh giá\n",
    "        print(\"Đang sử dụng phương pháp dự phòng (sách phổ biến)...\")\n",
    "        popular_books = ratings.filter(~col(\"BookID\").isin(rated_books)) \\\n",
    "                       .groupBy(\"BookID\", \"title\").agg(\n",
    "                           avg(\"Rating\").alias(\"avg_rating\"),\n",
    "                           count(\"Rating\").alias(\"rating_count\")\n",
    "                       ).filter(col(\"rating_count\") >= 5) \\\n",
    "                       .orderBy(desc(\"avg_rating\"), desc(\"rating_count\")) \\\n",
    "                       .limit(top_n)\n",
    "        \n",
    "        return popular_books\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tạo gợi ý: {str(e)}\")\n",
    "        # Trả về DataFrame trống nếu có lỗi\n",
    "        return spark.createDataFrame([], \"BookID STRING, title STRING, avg_rating FLOAT, rating_count INT\")\n",
    "\n",
    "# Lấy danh sách mẫu người dùng để thử nghiệm\n",
    "sample_users = ratings.select(\"UserID\").distinct().limit(5)\n",
    "User_ids = [row.UserID for row in sample_users.collect()]\n",
    "\n",
    "# Thử nghiệm hàm gợi ý\n",
    "test_user_id = User_ids[0]  # Lấy một người dùng từ mẫu\n",
    "print(f\"Gợi ý sách cho người dùng {test_user_id}:\")\n",
    "recommendations_df = recommend_books_for_user(test_user_id, top_n=10)\n",
    "\n",
    "# Hiển thị gợi ý\n",
    "if recommendations_df.count() > 0:\n",
    "    print(\"\\nSách được gợi ý:\")\n",
    "    recommendations_df.show(truncate=False)\n",
    "    \n",
    "    # Hiển thị thông tin chi tiết về sách\n",
    "    print(\"\\nThông tin chi tiết:\")\n",
    "    for i, book in enumerate(recommendations_df.collect(), 1):\n",
    "        book_id = book.BookID\n",
    "        title = book.title\n",
    "        avg_rating = book.avg_rating\n",
    "        count = book.rating_count\n",
    "        \n",
    "        # Tìm thể loại của sách\n",
    "        book_categories = books_with_categories.filter(col(\"title\") == title) \\\n",
    "                         .select(\"category_list\").collect()\n",
    "        categories = []\n",
    "        if book_categories and len(book_categories) > 0 and book_categories[0].category_list:\n",
    "            categories = book_categories[0].category_list\n",
    "            \n",
    "        print(f\"{i}. '{title}' (ID: {book_id})\")\n",
    "        print(f\"   Đánh giá: {avg_rating:.2f}/5 ({count} lượt)\")\n",
    "        if categories:\n",
    "            print(f\"   Thể loại: {', '.join(categories)}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Không tìm được gợi ý phù hợp\")\n",
    "\n",
    "# Thử nghiệm với các người dùng khác\n",
    "print(\"\\n=== Gợi ý cho tất cả người dùng mẫu ===\")\n",
    "for idx, user_id in enumerate(User_ids, 1):\n",
    "    print(f\"\\n--- Người dùng {idx}: {user_id} ---\")\n",
    "    \n",
    "    # Tạo gợi ý\n",
    "    user_recs = recommend_books_for_user(user_id, top_n=5)\n",
    "    \n",
    "    # Hiển thị gợi ý\n",
    "    if user_recs.count() > 0:\n",
    "        print(f\"Top 5 sách được gợi ý cho người dùng {user_id}:\")\n",
    "        user_recs.show(truncate=False)\n",
    "    else:\n",
    "        print(f\"Không tìm được gợi ý phù hợp cho người dùng {user_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gợi ý các sách phù hợp (item-item collaborative filtering)\n",
    "def find_similar_books(book_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Tìm các sách tương tự với một cuốn sách cụ thể\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_id : int\n",
    "        ID của cuốn sách\n",
    "    top_n : int\n",
    "        Số lượng sách tương tự cần tìm\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        DataFrame chứa các sách tương tự và độ tương tự\n",
    "    \"\"\"\n",
    "    # Lấy các yếu tố tiềm ẩn cho các sách\n",
    "    item_factors = model.itemFactors\n",
    "    \n",
    "    # Tìm vector yếu tố cho sách được chỉ định\n",
    "    book_factor = item_factors.filter(col(\"id\") == book_id).select(\"features\").first()\n",
    "    \n",
    "    if book_factor is None:\n",
    "        print(f\"Không tìm thấy thông tin cho sách có ID: {book_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Tính khoảng cách cosine giữa cuốn sách này và tất cả các sách khác\n",
    "    from pyspark.ml.functions import vector_to_array\n",
    "    from pyspark.sql.functions import arrays_zip, expr, array\n",
    "    \n",
    "    # Tính toán khoảng cách cosine\n",
    "    dot_product = expr(\"dotProduct(features, array_features)\")\n",
    "    norm_target = expr(\"sqrt(dotProduct(array_features, array_features))\")\n",
    "    norm_item = expr(\"sqrt(dotProduct(features, features))\")\n",
    "    \n",
    "    target_features = book_factor.features\n",
    "    \n",
    "    similar_books = item_factors.filter(col(\"id\") != book_id) \\\n",
    "                               .withColumn(\"array_features\", array([lit(f) for f in target_features])) \\\n",
    "                               .withColumn(\"similarity\", dot_product / (norm_target * norm_item)) \\\n",
    "                               .select(\"id\", \"similarity\") \\\n",
    "                               .orderBy(desc(\"similarity\")) \\\n",
    "                               .limit(top_n) \\\n",
    "                               .withColumnRenamed(\"id\", \"book_id\")\n",
    "    \n",
    "    # Join với dữ liệu sách để lấy thông tin chi tiết\n",
    "    result = similar_books.join(books_df, \"book_id\", \"left\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Thử nghiệm hàm tìm sách tương tự\n",
    "# Lấy một ID sách ngẫu nhiên\n",
    "sample_book_id = books_df.select(\"book_id\").limit(1).first().book_id\n",
    "print(f\"\\nTìm sách tương tự với sách có ID {sample_book_id}:\")\n",
    "\n",
    "similar_books_df = find_similar_books(sample_book_id, top_n=10)\n",
    "if similar_books_df:\n",
    "    sample_book = get_book_info(sample_book_id)\n",
    "    if sample_book:\n",
    "        print(f\"Sách gốc: '{sample_book['title']}' by {sample_book['author']}\")\n",
    "    \n",
    "    print(\"Các sách tương tự:\")\n",
    "    similar_books_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đóng SparkSession\n"
     ]
    }
   ],
   "source": [
    "# Đóng SparkSession\n",
    "spark.stop()\n",
    "print(\"Đã đóng SparkSession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
